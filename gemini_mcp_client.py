import json
import subprocess
import sys
import os
from typing import Dict, Any, List, Optional
import google.generativeai as genai


class MCPClient:
    """ç°¡å–®çš„ MCP å®¢æˆ¶ç«¯ï¼Œé€é stdio èˆ‡ MCP ä¼ºæœå™¨é€šè¨Š"""
    
    def __init__(self, server_script: str):
        self.server_script = server_script
        self.process = None
        
    def __enter__(self):
        """å•Ÿå‹•ä¼ºæœå™¨ç¨‹åº"""
        self.process = subprocess.Popen(
            [sys.executable, self.server_script],
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            bufsize=0
        )
        
        # è®€å–ä¼ºæœå™¨å•Ÿå‹•è¨Šæ¯
        ready_msg = self.process.stdout.readline()
        print(f"ğŸš€ {ready_msg.strip()}")
        return self
        
    def __exit__(self, exc_type, exc_val, exc_tb):
        """é—œé–‰ä¼ºæœå™¨ç¨‹åº"""
        if self.process:
            self.process.terminate()
            self.process.wait()
            
    def call_tool(self, tool: str, args: Dict[str, Any] = None) -> Dict[str, Any]:
        """å‘¼å« MCP å·¥å…·"""
        if not self.process:
            raise RuntimeError("å®¢æˆ¶ç«¯æœªå•Ÿå‹•")
            
        request = {
            "tool": tool,
            "args": args or {}
        }
        
        # ç™¼é€è«‹æ±‚
        request_json = json.dumps(request) + "\n"
        self.process.stdin.write(request_json)
        self.process.stdin.flush()
        
        # è®€å–å›æ‡‰
        response_line = self.process.stdout.readline()
        response = json.loads(response_line)
        
        return response


class GeminiMCPAgent:
    """ä½¿ç”¨ Gemini çš„æ™ºèƒ½ MCP ä»£ç†"""
    
    def __init__(self, api_key: str, mcp_client: MCPClient):
        genai.configure(api_key=api_key)
        
        # å˜—è©¦ä¸åŒçš„æ¨¡å‹åç¨±ï¼Œå„ªå…ˆä½¿ç”¨æœ€æ–°çš„ gemini-2.0-flash
        model_names = [
            'gemini-2.0-flash',
            'gemini-1.5-flash',
            'gemini-1.5-pro', 
            'gemini-pro',
            'models/gemini-2.0-flash',
            'models/gemini-1.5-flash',
            'models/gemini-1.5-pro'
        ]
        
        self.model = None
        for model_name in model_names:
            try:
                self.model = genai.GenerativeModel(model_name)
                print(f"âœ… ä½¿ç”¨æ¨¡å‹: {model_name}")
                break
            except Exception as e:
                print(f"âš ï¸  å˜—è©¦æ¨¡å‹ {model_name} å¤±æ•—: {str(e)}")
                continue
        
        if not self.model:
            # åˆ—å‡ºå¯ç”¨æ¨¡å‹
            try:
                available_models = list(genai.list_models())
                print("ğŸ“‹ å¯ç”¨çš„æ¨¡å‹:")
                for model in available_models:
                    if 'generateContent' in model.supported_generation_methods:
                        print(f"   - {model.name}")
                
                # ä½¿ç”¨ç¬¬ä¸€å€‹æ”¯æ´ generateContent çš„æ¨¡å‹
                for model in available_models:
                    if 'generateContent' in model.supported_generation_methods:
                        self.model = genai.GenerativeModel(model.name)
                        print(f"âœ… è‡ªå‹•é¸æ“‡æ¨¡å‹: {model.name}")
                        break
            except Exception as e:
                print(f"âŒ ç„¡æ³•åˆ—å‡ºå¯ç”¨æ¨¡å‹: {str(e)}")
        
        if not self.model:
            raise RuntimeError("ç„¡æ³•æ‰¾åˆ°å¯ç”¨çš„ Gemini æ¨¡å‹")
        
        self.mcp_client = mcp_client
        self.conversation_history = []
        
        # å¯ç”¨çš„å·¥å…·æè¿°
        self.available_tools = {
            "test": {
                "description": "æ¸¬è©¦ä¼ºæœå™¨æ˜¯å¦æ­£å¸¸é‹è¡Œ",
                "parameters": {}
            },
            "search": {
                "description": "åœ¨è©æ¬ºè³‡æ–™é›†ä¸­æœå°‹ç›¸é—œæ–‡ä»¶",
                "parameters": {
                    "query": "æœå°‹æŸ¥è©¢å­—ä¸²",
                    "top_k": "è¿”å›çš„çµæœæ•¸é‡ (é è¨­: 5)"
                }
            },
            "expand_search": {
                "description": "ä½¿ç”¨ Gemini æ“´å……æŸ¥è©¢å¾Œå†æœå°‹",
                "parameters": {
                    "query": "æœå°‹æŸ¥è©¢å­—ä¸²",
                    "top_k": "è¿”å›çš„çµæœæ•¸é‡ (é è¨­: 5)"
                }
            },
            "read_fraud_data": {
                "description": "è®€å–å®Œæ•´çš„è©æ¬ºåˆ¤æ±ºæ‘˜è¦è³‡æ–™é›†",
                "parameters": {}
            },
            "evaluate_fraud": {
                "description": "è©•ä¼° BM25 åœ¨è©æ¬ºæŸ¥è©¢ä¸Šçš„æ•ˆèƒ½",
                "parameters": {
                    "top_k": "è©•ä¼°æ™‚è€ƒæ…®çš„å‰ k å€‹çµæœ (é è¨­: 10)"
                }
            }
        }
    
    def _create_system_prompt(self) -> str:
        """å»ºç«‹ç³»çµ±æç¤º"""
        tools_desc = "\n".join([
            f"- {name}: {info['description']}"
            for name, info in self.available_tools.items()
        ])

        return f"""ä½ æ˜¯ä¸€å€‹æ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥å¹«åŠ©ä½¿ç”¨è€…æŸ¥è©¢å’Œåˆ†æè©æ¬ºç›¸é—œè³‡æ–™ã€‚

ä½ æœ‰ä»¥ä¸‹å¯ç”¨çš„å·¥å…·ï¼š
{tools_desc}

é€šå¸¸è«‹å…ˆä½¿ç”¨ `search` å·¥å…·æª¢ç´¢ï¼Œè§€å¯Ÿçµæœå¾Œå¦‚æœ‰éœ€è¦å†ä½¿ç”¨
`expand_search` é€é Gemini æ“´å……æŸ¥è©¢å¾Œé‡æ–°æœå°‹ã€‚

è«‹æ ¹æ“šä½¿ç”¨è€…çš„å•é¡Œï¼Œåˆ¤æ–·æ˜¯å¦éœ€è¦ä½¿ç”¨é€™äº›å·¥å…·ã€‚å¦‚æœéœ€è¦ä½¿ç”¨å·¥å…·ï¼Œè«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼š
{{
    "action": "use_tool",
    "tool": "å·¥å…·åç¨±",
    "args": {{"åƒæ•¸å": "åƒæ•¸å€¼"}},
    "reasoning": "ç‚ºä»€éº¼è¦ä½¿ç”¨é€™å€‹å·¥å…·çš„åŸå› "
}}

å¦‚æœä¸éœ€è¦ä½¿ç”¨å·¥å…·ï¼Œè«‹ç›´æ¥å›ç­”ä½¿ç”¨è€…çš„å•é¡Œï¼š
{{
    "action": "respond",
    "response": "ä½ çš„å›ç­”"
}}

è«‹ç”¨ç¹é«”ä¸­æ–‡å›æ‡‰ã€‚"""

    def _analyze_user_input(self, user_input: str) -> Dict[str, Any]:
        """åˆ†æä½¿ç”¨è€…è¼¸å…¥ä¸¦æ±ºå®šæ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·"""
        
        # å»ºç«‹å°è©±æ­·å²
        history_text = "\n".join([
            f"ä½¿ç”¨è€…: {entry['user']}\nåŠ©æ‰‹: {entry['assistant']}"
            for entry in self.conversation_history[-3:]  # åªä¿ç•™æœ€è¿‘3è¼ªå°è©±
        ])
        
        prompt = f"""
{self._create_system_prompt()}

å°è©±æ­·å²ï¼š
{history_text}

ä½¿ç”¨è€…æœ€æ–°å•é¡Œï¼š{user_input}

è«‹åˆ†æé€™å€‹å•é¡Œä¸¦æ±ºå®šä¸‹ä¸€æ­¥è¡Œå‹•ã€‚
"""
        
        try:
            # ä½¿ç”¨æ›´å®‰å…¨çš„ç”Ÿæˆé…ç½®
            generation_config = genai.types.GenerationConfig(
                temperature=0.1,
                max_output_tokens=1000,
            )
            
            response = self.model.generate_content(
                prompt,
                generation_config=generation_config
            )
            
            # å˜—è©¦è§£æ JSON å›æ‡‰
            response_text = response.text.strip()
            
            # ç§»é™¤å¯èƒ½çš„ markdown ä»£ç¢¼å¡Šæ¨™è¨˜
            if response_text.startswith("```json"):
                response_text = response_text[7:]
            if response_text.endswith("```"):
                response_text = response_text[:-3]
            
            return json.loads(response_text)
            
        except json.JSONDecodeError:
            # å¦‚æœç„¡æ³•è§£æ JSONï¼Œå‡è¨­æ˜¯ç›´æ¥å›æ‡‰
            return {
                "action": "respond",
                "response": response.text if hasattr(response, 'text') else str(response)
            }
        except Exception as e:
            return {
                "action": "respond",
                "response": f"æŠ±æ­‰ï¼Œæˆ‘åœ¨è™•ç†æ‚¨çš„è«‹æ±‚æ™‚é‡åˆ°äº†å•é¡Œï¼š{str(e)}"
            }
    
    def _execute_tool(self, tool_name: str, args: Dict[str, Any]) -> str:
        """åŸ·è¡Œ MCP å·¥å…·ä¸¦æ ¼å¼åŒ–çµæœ"""
        try:
            response = self.mcp_client.call_tool(tool_name, args)
            
            if "error" in response:
                return f"âŒ å·¥å…·åŸ·è¡ŒéŒ¯èª¤ï¼š{response['error']}"
            
            result = response["result"]
            
            # æ ¹æ“šä¸åŒå·¥å…·æ ¼å¼åŒ–è¼¸å‡º
            if tool_name == "test":
                return f"âœ… {result}"
            
            elif tool_name == "search":
                if not result:
                    return "ğŸ” æ²’æœ‰æ‰¾åˆ°ç›¸é—œçµæœ"

                formatted_results = ["ğŸ” æœå°‹çµæœï¼š"]
                for i, item in enumerate(result[:5], 1):
                    formatted_results.append(
                        f"\n{i}. æ–‡ä»¶ID: {item['doc_id']}"
                        f"\n   ç›¸é—œåº¦: {item['score']:.4f}"
                        f"\n   å…§å®¹: {item['text'][:200]}{'...' if len(item['text']) > 200 else ''}\n"
                    )
                return "\n".join(formatted_results)

            elif tool_name == "expand_search":
                results = result.get("results", [])
                expanded_query = result.get("expanded_query", "")
                if not results:
                    return f"ğŸ” æ“´å……å¾ŒæŸ¥è©¢ï¼š{expanded_query}\næ²’æœ‰æ‰¾åˆ°ç›¸é—œçµæœ"

                formatted_results = [f"ğŸ” æ“´å……å¾ŒæŸ¥è©¢ï¼š{expanded_query}"]
                for i, item in enumerate(results[:5], 1):
                    formatted_results.append(
                        f"\n{i}. æ–‡ä»¶ID: {item['doc_id']}"
                        f"\n   ç›¸é—œåº¦: {item['score']:.4f}"
                        f"\n   å…§å®¹: {item['text'][:200]}{'...' if len(item['text']) > 200 else ''}\n"
                    )
                return "\n".join(formatted_results)
            
            elif tool_name == "read_fraud_data":
                return f"ğŸ“Š è©æ¬ºè³‡æ–™é›†åŒ…å« {len(result)} ç­†è¨˜éŒ„"
            
            elif tool_name == "evaluate_fraud":
                return (f"ğŸ“ˆ è©•ä¼°çµæœï¼š\n"
                       f"   æº–ç¢ºç‡: {result['accuracy']:.4f}\n"
                       f"   MRR: {result['mrr']:.4f}")
            
            else:
                return f"ğŸ“‹ çµæœï¼š{json.dumps(result, ensure_ascii=False, indent=2)}"
                
        except Exception as e:
            return f"âŒ åŸ·è¡Œå·¥å…·æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}"
    
    def chat(self, user_input: str) -> str:
        """è™•ç†ä½¿ç”¨è€…è¼¸å…¥ä¸¦å›æ‡‰"""
        print(f"ğŸ¤” åˆ†æä¸­...")
        
        # åˆ†æä½¿ç”¨è€…è¼¸å…¥
        analysis = self._analyze_user_input(user_input)
        
        if analysis["action"] == "use_tool":
            tool_name = analysis["tool"]
            args = analysis.get("args", {})
            reasoning = analysis.get("reasoning", "")
            
            print(f"ğŸ”§ æº–å‚™ä½¿ç”¨å·¥å…·: {tool_name}")
            if reasoning:
                print(f"ğŸ’­ åŸå› : {reasoning}")
            
            # åŸ·è¡Œå·¥å…·
            tool_result = self._execute_tool(tool_name, args)
            
            # è®“ Gemini è§£é‡‹çµæœ
            explain_prompt = f"""
æ ¹æ“šä»¥ä¸‹å·¥å…·åŸ·è¡Œçµæœï¼Œè«‹ç”¨è‡ªç„¶èªè¨€å‘ä½¿ç”¨è€…è§£é‡‹ï¼š

ä½¿ç”¨è€…å•é¡Œï¼š{user_input}
å·¥å…·çµæœï¼š{tool_result}

è«‹æä¾›æ¸…æ¥šã€æœ‰ç”¨çš„è§£é‡‹ã€‚
"""
            
            try:
                explanation = self.model.generate_content(explain_prompt)
                final_response = f"{tool_result}\n\nğŸ’¡ {explanation.text}"
            except:
                final_response = tool_result
            
        else:
            final_response = analysis["response"]
        
        # è¨˜éŒ„å°è©±æ­·å²
        self.conversation_history.append({
            "user": user_input,
            "assistant": final_response
        })
        
        return final_response


def main():
    """ä¸»ç¨‹å¼"""
    # æª¢æŸ¥ API é‡‘é‘°
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        print("âŒ è«‹è¨­å®š GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸")
        print("   export GEMINI_API_KEY=your_api_key_here")
        return
    
    print("ğŸŒŸ Gemini MCP æ™ºèƒ½åŠ©æ‰‹å•Ÿå‹•ä¸­...")
    
    try:
        with MCPClient("mcp_server.py") as mcp_client:
            agent = GeminiMCPAgent(api_key, mcp_client)
            
            print("\nâœ¨ åŠ©æ‰‹å·²æº–å‚™å°±ç·’ï¼æ‚¨å¯ä»¥è©¢å•é—œæ–¼è©æ¬ºè³‡æ–™çš„ä»»ä½•å•é¡Œã€‚")
            print("ğŸ’¡ ä¾‹å¦‚ï¼š")
            print("   - æœå°‹ money laundering ç›¸é—œæ–‡ä»¶")
            print("   - è©æ¬ºè³‡æ–™é›†æœ‰å¤šå°‘ç­†è³‡æ–™ï¼Ÿ")
            print("   - è©•ä¼°ä¸€ä¸‹æœå°‹ç³»çµ±çš„æ•ˆèƒ½")
            print("   - è¼¸å…¥ 'quit' æˆ– 'exit' çµæŸ\n")
            
            while True:
                try:
                    user_input = input("ğŸ‘¤ æ‚¨: ").strip()
                    
                    if user_input.lower() in ['quit', 'exit', 'é€€å‡º', 'çµæŸ']:
                        print("ğŸ‘‹ å†è¦‹ï¼")
                        break
                    
                    if not user_input:
                        continue
                    
                    response = agent.chat(user_input)
                    print(f"\nğŸ¤– åŠ©æ‰‹: {response}\n")
                    
                except KeyboardInterrupt:
                    print("\nğŸ‘‹ å†è¦‹ï¼")
                    break
                except Exception as e:
                    print(f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
                    
    except Exception as e:
        print(f"âŒ ç„¡æ³•å•Ÿå‹• MCP ä¼ºæœå™¨ï¼š{str(e)}")
        print("è«‹ç¢ºèª mcp_server.py æª”æ¡ˆå­˜åœ¨ä¸”ç›¸é—œä¾è³´å·²å®‰è£")


if __name__ == "__main__":
    main()